<!DOCTYPE html>
<html lang="en"><head>  
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <title>Computer Vision Course Project
  | ECE, Virginia Tech | Fall 2021: ECE 4554/5554</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="author" content="">

<!-- Le styles -->  
  <link href="css/bootstrap.css" rel="stylesheet">
<style>
body {
padding-top: 60px; /* 60px to make the container go all the way to the bottom of the topbar */
}
.vis {
color: #3366CC;
}
.data {
color: #FF9900;
}
</style>
  
<link href="css/bootstrap-responsive.min.css" rel="stylesheet">

<!-- HTML5 shim, for IE6-8 support of HTML5 elements --><!--[if lt IE 9]>
<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->
</head>

<body>
<div class="container">
<div class="page-header">

<!-- Title and Name --> 
<h1>Hand Gestures to Controll Moving Objects</h1> 
<span style="font-size: 20px; line-height: 1.5em;"><strong>Alexander Nguyen, Ryan Hua</strong></span><br>
<span style="font-size: 18px; line-height: 1.5em;">Fall 2023 ECE 4554/5554 Computer Vision: Course Project</span><br>
<span style="font-size: 18px; line-height: 1.5em;">Virginia Tech</span>
<hr>

Please see <a href="http://vision.cs.utexas.edu/projects/adapted_attributes/">this</a> for an example of how to lay out the various details of your project. You may need to provide more details than this, because you will not be submitting an associated paper to accompany the webpage. So the page should be self-contained.

<!-- Goal -->
<h3>Abstract</h3>

<p>Robotics and automonous systems are beoming more and more prevalent in the world today. 
  This also means that there is a demand for more innovative interactions among these systems.
  The ability to control a moving object through hand gestures would allow for significant improvements in the user experience. 
  It would allow for a hands-free interaction, in which, the user does not need to be in the same vicinity as the machine. 
  A more practical functionality would be to control systems at a distance in cases where the environment is dangerous or inaccessible.  
  Overall, our goal is to tackle the challenge of interpreting certain hand gestures with different actionable commands. 
  This is a starting point and could allow for progress into a wide range of applications.</p>
<br><br>
<!-- figure -->
<h3>Teaser figure</h3>
A figure that conveys the main idea behind the project or the main application being addressed.
<br><br>
<!-- Main Illustrative Figure --> 
<div style="text-align: center; display: flex; justify-content: space-around;">
<img style="height: 200px;" alt="" src="teaser1.png">
<img style="height: 200px;" alt="" src="teaser2.png">
</div>

<br><br>
<!-- Introduction -->
<h3>Introduction</h3>
<p>Robotics and automonous systems are beoming more and more prevalent in the world today. 
  This also means that there is a demand for more innovative interactions among these systems.
  The ability to control a moving object through hand gestures would allow for significant improvements in the user experience. 
  It would allow for a hands-free interaction, in which, the user does not need to be in the same vicinity as the machine. 
  A more practical functionality would be to control systems at a distance in cases where the environment is dangerous or inaccessible.  
  Overall, our goal is to tackle the challenge of interpreting certain hand gestures with different actionable commands. 
  This is a starting point and could allow for progress into a wide range of applications.</p>

<br><br>
<!-- Approach -->
<h3>Approach</h3>
<p>First, we would collect a dataset of images consisting of different hand gestures with labels in order to train the deep learning model. We would then preprocess the image to extract the hand region or to enhance certain features. For example, we could reduce noise using a Gaussian Kernel, isolate the hand using contour extraction, alter the pixels to make the intensities more prominent using thresholds, etc. We can use a 3x3 or 5x5 kernel. For the contour extraction, we can use the OpenCV library to draw the hand. We would probably use a threshold of 127, to differentiate the intensity of the new pixel. ashni Haria, Archanasri Subramanian, Nivedhitha Asokkumar, Shristi Poddar, Jyothi S Nayak, Hand Gesture Recognition for Human Computer Interaction, Procedia Computer Science, Volume 115, 2017, Pages 367-374, ISSN 1877-0509, https://doi.org/10.1016/j.procs.2017.09.092. (https://www.sciencedirect.com/science/article/pii/S1877050917319130)
After that, we can use pre-trained convolutional neural network as the model for classifying the different gestures. Some pre-trained models could be Resnet or VGG-16. We can alter some parameters. Additionally, we could add on more custom layers to the model or fine-tune it. A layer of batch normalization is added after the 4th convolution block to normalize the output of the layers and prevent the model overfitting.
Mapada, Carl. “Hand Gesture Recognition.” Medium, Medium, 30 Dec. 2021, medium.com/@cmmapada/hand-gesture-recognition-5cdc0e380854.
Ewe, E.L.R.; Lee, C.P.; Kwek, L.C.; Lim, K.M. Hand Gesture Recognition via Lightweight VGG16 and Ensemble Classifier. Appl. Sci. 2022, 12, 7643. https://doi.org/10.3390/app12157643</p>


<br><br>
<!-- Results -->
<h3>Experiments and results</h3>
Provide details about the experimental set up (number of images/videos, number of datasets you experimented with, train/test split if you used machine learning algorithms, etc.). Describe the evaluation metrics you used to evaluate how well your approach is working. Include clear figures and tables, as well as illustrative qualitative examples if appropriate. Be sure to include obvious baselines to see if your approach is doing better than a naive approach (e.g. for classification accuracy, how well would a classifier do that made random decisions?). Also discuss any parameters of your algorithms, and tell us how you set the values of those parameters. You can also show us how the performance varies as you change those parameter values. Be sure to discuss any trends you see in your results, and explain why these trends make sense. Are the results as expected? Why?

<br><br>

<!-- Main Results Figure --> 
<div style="text-align: center;">
<img style="height: 300px;" alt="" src="results.png">
</div>
<br><br>

<!-- Results -->
<h3>Qualitative results</h3>
Show several visual examples of inputs/outputs of your system (success cases and failures) that help us better understand your approach.
<br><br>

<!-- Main Results Figure --> 
<div style="text-align: center;">
<img style="height: 300px;" alt="" src="qual_results.png">
</div>
<br><br>

<!-- Conclusion -->
<h3>Conclusion</h3>
This report has described .... Briefly summarize what you have done. 
<br><br>

<!-- References -->
<h3>References</h3>
Provide a list of references to other work that supported your project.
<br><br>


  <hr>
  <footer> 
  <p>© Alexander Nguyen, Ryan Hua</p>
  </footer>
</div>
</div>

<br><br>

</body></html>